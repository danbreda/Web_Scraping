{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613e4d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#WebScraping do Kabum, produtos mais novos no site\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Website a fazer scraping\n",
    "website = 'https://www.kabum.com.br/acabaramdechegar'\n",
    "\n",
    "# headers para não dar ruim no site ao raspar\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'\n",
    "}\n",
    "site = requests.get(website, headers=headers)\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "# Fazer o calculo pra fazer a quantidade de páginas total\n",
    "qtd_itens = soup.find('div', id='listingCount').get_text().strip()\n",
    "\n",
    "# Limpar o valor\n",
    "index = qtd_itens.find(' ')\n",
    "qtd = qtd_itens[:index]\n",
    "\n",
    "# Verificar ultima pagina, 'ceil' para quebrar pra cima a numeração\n",
    "ultima_pagina = math.ceil(int(qtd)/20)\n",
    "\n",
    "# Dicionario para armazenar os dados\n",
    "dict_produtos = {'descricao':[], 'preco':[], 'frete_gratis':[]}\n",
    "\n",
    "# Fazendo a raspagem (todas as páginas é muita página)\n",
    "for i in range(1, ultima_pagina - 450 ):\n",
    "    \n",
    "    url_page = f'https://www.kabum.com.br/acabaramdechegar?page_number={i}&page_size=20&facet_filters=&sort=-date_product_arrived'\n",
    "    site = requests.get(url_page, headers=headers)\n",
    "    soup = BeautifulSoup(site.content, 'html.parser')\n",
    "    \n",
    "    # Criando uma variável para armazenar os cards principais, organizar melhor pro for sequente \n",
    "    produtos = soup.find_all('div', class_=re.compile('productCard'))\n",
    "    \n",
    "    for produto in produtos:\n",
    "        \n",
    "        # try pra caso não tiver a info, não dar erro no código\n",
    "        try:\n",
    "            descricao = produto.find('span', class_=re.compile('nameCard')).get_text().strip()\n",
    "        except:\n",
    "            descricao = 'n/a'\n",
    "       \n",
    "        try:\n",
    "            preco = produto.find('span', class_=re.compile('priceCard')).get_text().strip()\n",
    "        except:\n",
    "            preco = 'n/a'\n",
    "            \n",
    "        try:\n",
    "            frete_gratis = produto.find('div', class_=re.compile('freeShippingTagCard')).get_text().strip()\n",
    "        except:\n",
    "            frete_gratis = 'n/a'\n",
    "            \n",
    "        print(descricao, preco, frete_gratis)\n",
    "        \n",
    "        # Armazenando no dicionário os dados\n",
    "        dict_produtos['descricao'].append(descricao)\n",
    "        dict_produtos['preco'].append(preco)\n",
    "        dict_produtos['frete_gratis'].append(frete_gratis)\n",
    "\n",
    "# Criando um dataframe com o dicionário e mandando pra um arquivo .csv    \n",
    "df = pd.DataFrame(dict_produtos)\n",
    "df.to_csv('C:/Users/Danilo/Documents/repos/novidades_kabum.csv', encoding='utf-8', sep=';')\n",
    "\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
